{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing the necessary libraries and setting up the paths for the files. But before doing anything, we need the EEG data to work with. Use the `ds003846-1sh` script in this repo to download the data (it will be saved in the`ds003846-1.0.0` folder). The data is organized into folders by subject, and each folder has sessions for different conditions. We’ll be doing our analysis on subject 1 (sub-1). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "base_path = Path(\"./ds003846-2.0.2\")\n",
    "subject = \"sub-02\"\n",
    "session = \"ses-EMS\"\n",
    "data_path = base_path / subject / session / \"eeg\"\n",
    "\n",
    "# define paths\n",
    "base_path = Path(\"./ds003846-2.0.2\")\n",
    "subject = \"sub-02\"\n",
    "data_paths = {\n",
    "    \"ses-EMS\": base_path / subject / \"ses-EMS\" / \"eeg\",\n",
    "    \"ses-Visual\": base_path / subject / \"ses-Visual\" / \"eeg\",\n",
    "    \"ses-Vibro\": base_path / subject / \"ses-Vibro\" / \"eeg\"\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Load the data (Step 1)**  \n",
    "\n",
    "First, we’ll load EEG data for all sessions (EMS, Visual, and Vibro) and apply 10-20 montage. The dataset uses channel names like `BrainVision RDA_Fp1`, which won’t match MNE’s standard montages. We’ll strip the prefix and apply the 10-20 montage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load the EEG Data for subject 1 for all sessions/conditions\n",
    "raw_sessions = {}\n",
    "for session, path in data_paths.items():\n",
    "    print(f\"Loading data for {session}...\")\n",
    "    vhdr_file = path / f\"{subject}_{session}_task-PredictionError_eeg.vhdr\"\n",
    "    raw = mne.io.read_raw_brainvision(str(vhdr_file), preload=True)\n",
    "    raw_sessions[session] = raw\n",
    "    # print some metadata\n",
    "    print(f\"{session}: Channels={raw.info['nchan']}, Sampling rate={raw.info['sfreq']} Hz, Samples={raw.n_times}, Duration={raw.times[-1]:.2f} s\")\n",
    "    print(f\"Original channels for {session}: {raw.info['ch_names']}\")\n",
    "\n",
    "\n",
    "# The channel names in the dataset have a prefix (\"BrainVision RDA_\") that is specific to the recording system\n",
    "# We need to remove this prefix to match the standard EEG channel naming convention (e.g., \"Fp1\", \"Fz\")\n",
    "for session, raw in raw_sessions.items():\n",
    "    print(f\"Cleaning channel names for {session}...\")\n",
    "    raw.rename_channels(lambda x: x.replace(\"BrainVision RDA_\", \"\"))\n",
    "    montage = mne.channels.make_standard_montage(\"standard_1020\")\n",
    "    raw.set_montage(montage)\n",
    "    raw.plot_sensors(kind=\"topomap\", show_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter and downsample (Step 2)**  \n",
    "\n",
    "We start the preporcessing --> filter and downsample the data. The paper says: “The raw EEG data was re-sampled to 250 Hz, high-pass filtered at 1 Hz, and low-pass filtered at 125 Hz.” However, filtering should happen before downsampling to avoid aliasing, so we’re doing it in that order instead. Their MATLAB does the same, so no difference here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for session, raw in raw_sessions.items():\n",
    "    # let's first check the frequency range of the data before bandpass\n",
    "    psd, freqs = raw.compute_psd().get_data(return_freqs=True)\n",
    "    max_freq = freqs.max()\n",
    "    min_freq = freqs.min()\n",
    "    print(f\"Frequency range in the data: {min_freq} Hz to {max_freq} Hz\")\n",
    "    # Filter the Data (1–125 Hz bandpass)\n",
    "    print(f\"Filtering and downsampling for {session}...\")\n",
    "    raw.filter(l_freq=1, h_freq=124.9)  # Bandpass filter (1-125 Hz)\n",
    "    raw.resample(250)  # Downsample to 250 Hz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Re-referencing (Step 3)**  \n",
    "In the paper, they re-reference the data to the average of all electrodes, including FCz. We’ll follow that here too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for session, raw in raw_sessions.items():\n",
    "    print(f\"Re-referencing data for {session}...\")\n",
    "    raw.set_eeg_reference(\"average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Epoch Rejection **\n",
    "# The paper divides data into 1-second epochs and removes the noisiest 15%. This is skipped in our implementation to retain continuous data for ICA, simplifying the pipeline.\n",
    "# The paper mentions rejecting 15% of the noisiest 1-second epochs before ICA to remove extreme artifacts. However, for simplicity, we skip this step.\n",
    "# Skipping this step retains more data for analysis, but we acknowledge it might slightly reduce the quality of ICA results.\n",
    "\n",
    "\n",
    "# for session, raw in raw_sessions.items():\n",
    "#     print(f\"Rejecting 15% of noisiest epochs for {session}...\")\n",
    "#     # Use autoreject or similar methods here if needed\n",
    "#     pass\n",
    "\n",
    "# %% [markdown]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**ICA analysis (step 4)**\n",
    "\n",
    "Now we perform ICA analysis to remove artifacts like eye blinks and line noise.\n",
    "The paper also does this but after their intial 1 second window epoching and noisy epochs removal. We think this might be because it helps the ICA result when the data is clean. But in our pipeline we directly do the ICA analysis on the raw continous data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "ica_sessions = {}\n",
    "for session, raw in raw_sessions.items():\n",
    "    print(f\"Running ICA for {session}...\")\n",
    "    ica = mne.preprocessing.ICA(n_components=20, random_state=42, max_iter=\"auto\")\n",
    "    ica.fit(raw)\n",
    "    ica.plot_components()  # Inspect components manually\n",
    "\n",
    "    # TO DO: we need to identify the bad components by visually inspecting, not sure how to interpret the plots\n",
    "    ica.exclude = []  # Adjust based on visual inspection\n",
    "    ica.apply(raw)\n",
    "    ica_sessions[session] = raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ERP-Specific Filtering (Step 5)**\n",
    "\n",
    "To isolate ERP-related frequencies, the paper specifies filtering the data at 0.2–35 Hz. This helps focus on the relevant signals\n",
    "and is applied to the ICA-cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for session, raw in ica_sessions.items():\n",
    "    print(f\"Filtering for ERP analysis in {session}...\")\n",
    "    raw.filter(l_freq=0.2, h_freq=35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Epoching around stimulus (step 6)**\n",
    "\n",
    "We create epochs aligned to the stimulus event `box:touched` which is the moment of object selection. In the paper they state \"Then we sliced it between -0.3 seconds to 0.7 seconds around the stimulus onset, i.e. the moment of object selection\". We think the `box:touched` probably correponds to the \"moment of object selection\" so thats what we are using to align out epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_event()\n",
    "    event_id = {\"box:touched\": 2}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_sessions = {}\n",
    "tmin, tmax = -0.3, 0.7\n",
    "event_id = {\"normal\": 2, \"conflict\": 3}\n",
    "\n",
    "for session, raw in ica_sessions.items():\n",
    "    print(f\"Creating stimulus-aligned epochs for {session}...\")\n",
    "    # Extract events\n",
    "    events_file = data_paths[session] / f\"{subject}_{session}_task-PredictionError_events.tsv\"\n",
    "    events_df = pd.read_csv(events_file, sep=\"\\t\")\n",
    "    print(events_df.head(3))\n",
    "\n",
    "    # Map events\n",
    "    events = []\n",
    "    for _, row in events_df.iterrows():\n",
    "        event_dict = dict(item.split(\":\") for item in row[\"value\"].split(\";\"))\n",
    "\n",
    "        if \"box\" in event_dict and event_dict[\"box\"] == \"touched\":\n",
    "            sample = int(row[\"sample\"])\n",
    "\n",
    "            events.append([sample, 0, event_id[event_dict[\"normal_or_conflict\"]]])\n",
    "\n",
    "    events = np.array(events)\n",
    "    # Epoching, drop duplicate event too\n",
    "    epochs = mne.Epochs(\n",
    "        raw, events, event_id=event_id, tmin=tmin, tmax=tmax,\n",
    "        baseline=(None, 0), preload=True, event_repeated=\"drop\"\n",
    "    )\n",
    "    epochs_sessions[session] = epochs\n",
    "    print(f\"Extracted {len(epochs)} epochs for {session}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Epoch Rejection (Step 7)**\n",
    "\n",
    "Following the paper, we reject the 10% noisiest epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for session, epochs in epochs_sessions.items():\n",
    "    print(f\"Rejecting 10% of noisiest epochs for {session}...\")\n",
    "    reject_criteria = dict(eeg=200e-6)  # need to find a good threshold\n",
    "    epochs.drop_bad(reject=reject_criteria)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ERP Analysis (step 8)**\n",
    "\n",
    "In this step, we calculate and visualize the ERP by averaging the epochs. However, unlike the paper, we are not separating the epochs into matching and non-matching trials because the dataset does not include specific markers for this. A possible workaround could involve analyzing the order of events (e.g., box:touched, visual:off, etc.), but this would require additional assumptions.\n",
    "\n",
    "Also, the paper mentions focusing on the FCz channel for ERP analysis, but this channel is not present in the dataset for participant 1. Therefore, we use the Fz channel as an alternative for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for session, epochs in epochs_sessions.items():\n",
    "    print(f\"Computing ERPs for {session}...\")\n",
    "\n",
    "    # Debugging Step: Check channel names\n",
    "    print(f\"Channels available in {session}: {epochs.info['ch_names']}\")\n",
    "\n",
    "    # Use FCz if available, otherwise default to Fz\n",
    "    print(epochs.info[\"ch_names\"])\n",
    "    channel_to_use = \"FCz\" if \"FCz\" in epochs.info[\"ch_names\"] else \"Fz\"\n",
    "\n",
    "    if channel_to_use not in epochs.info[\"ch_names\"]:\n",
    "        print(f\"Warning: Neither FCz nor Fz found in {session}. Skipping this session.\")\n",
    "        continue  # Skip the session if neither FCz nor Fz is available\n",
    "\n",
    "    print(f\"Using {channel_to_use} for ERP computation in {session}.\")\n",
    "    # evoked = epochs[\"box:touched\"].average(picks=channel_to_use)\n",
    "    evoked = epochs[\"normal\"].average(picks=channel_to_use)\n",
    "    # Plot the ERP\n",
    "    fig = evoked.plot()\n",
    "    fig.suptitle(f\"ERP for box:touched ({channel_to_use}) in {session}\")  # Add a descriptive title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for session, epochs in epochs_sessions.items():\n",
    "    print(f\"Computing ERPs for {session}...\")\n",
    "\n",
    "    # Debugging Step: Check channel names\n",
    "    print(f\"Channels available in {session}: {epochs.info['ch_names']}\")\n",
    "\n",
    "    # Use FCz if available, otherwise default to Fz\n",
    "    print(epochs.info[\"ch_names\"])\n",
    "    channel_to_use = \"FCz\" if \"FCz\" in epochs.info[\"ch_names\"] else \"Fz\"\n",
    "\n",
    "    if channel_to_use not in epochs.info[\"ch_names\"]:\n",
    "        print(f\"Warning: Neither FCz nor Fz found in {session}. Skipping this session.\")\n",
    "        continue  # Skip the session if neither FCz nor Fz is available\n",
    "\n",
    "    print(f\"Using {channel_to_use} for ERP computation in {session}.\")\n",
    "    # # evoked = epochs[\"box:touched\"].average(picks=channel_to_use)\n",
    "    # evoked = epochs[\"conflict\"].average(picks=channel_to_use)\n",
    "    # fig = evoked.plot()\n",
    "    # fig.suptitle(f\"ERP for conflict ({channel_to_use}) in {session}\")  # Add a descriptive title\n",
    "\n",
    "    # Compute evoked responses for both conditions\n",
    "    evoked_conflict = epochs[\"conflict\"].average(picks=channel_to_use)\n",
    "    evoked_normal = epochs[\"normal\"].average(picks=channel_to_use)\n",
    "\n",
    "    # Create a new figure for plotting\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # Plot for conflict\n",
    "    evoked_conflict.plot(titles=f\"ERP for conflict ({channel_to_use}) in {session}\")\n",
    "\n",
    "    # Plot for normal in a new figure\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    evoked_normal.plot(titles=f\"ERP for normal ({channel_to_use}) in {session}\")\n",
    "\n",
    "    plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
